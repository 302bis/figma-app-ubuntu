{"version":3,"file":"ContentDefinedChunker.js","sourceRoot":"","sources":["../src/ContentDefinedChunker.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;AACA,AAAO,AAAE,AAAI,AAAE,AAAM,AAAY;;;;;;AACjC,AAAO,AAAE,AAAK,AAAE,AAAM,AAAgB,AAEtC,AAAM;;;;;AACE,AAAa,iBAAnB,AAAK,CAAe,AAAU,IAAE,AAAa,OAAE,AAAW,KAAE,AAAY;;AACtE,kBAAM,AAAQ,WAAG,AAAG,MAAG,AAAK;AAC5B,kBAAM,AAAM,SAAG,AAAM,OAAC,AAAW,YAAC,AAAI,KAAC,AAAG,IAAC,AAAC,IAAG,AAAI,OAAG,AAAI,MAAE,AAAQ,AAAC,AAAC;AAEtE,kBAAM,AAAK,QAAG,AAAK,AAAE;AACrB,kBAAM,AAAO,UAAG,AAAE;AAClB,kBAAM,AAAG,MAAG,AAAC,IAAG,AAAI;AACpB,AAAkD;AAClD,kBAAM,AAAG,MAAG,AAAE,KAAG,AAAI;AACrB,AAAK,kBAAC,AAAS,UAAC,AAAO,SAAE,AAAG,KAAE,AAAG,AAAC;AAElC,kBAAM,AAAS,YAAkB,AAAE;AACnC,kBAAM,AAAQ,WAAkB,AAAE;AAElC,gBAAI,AAAc,iBAAkB,AAAI;AACxC,gBAAI,AAAU,aAAG,AAAK;AACtB,mBAAO,AAAI,MAAE,AAAC;AACZ,sBAAM,AAAgB,mBAAG,AAAI,KAAC,AAAG,IAAC,AAAG,MAAG,AAAU,YAAE,AAAM,OAAC,AAAM,AAAC;AAClE,sBAAM,AAAI,0CAAC,AAAE,IAAE,AAAM,QAAE,AAAC,GAAE,AAAgB,kBAAE,AAAU,AAAC;AAEvD,sBAAM,AAAU,aAAW,AAAM,OAAC,AAAM,WAAK,AAAgB,AAAC,AAAC,mBAAC,AAAM,AAAC,AAAC,SAAC,AAAM,OAAC,AAAK,MAAC,AAAC,GAAE,AAAgB,AAAC;AAC1G,sBAAM,AAAK,QAAkB,AAAE;AAC/B,AAAK,sBAAC,AAAW,YAAC,CAAC,AAAU,AAAC,aAAE,AAAK,AAAC;AAEtC,oBAAI,AAAU,aAAG,AAAC;AAClB,AAAG,AAAC,qBAAC,MAAM,AAAI,QAAI,AAAK,AAAC,OAAC,AAAC;AACzB,AAAQ,6BAAC,AAAI,KAAC,AAAI,AAAC;AACnB,wBAAI,AAAQ,WAAG,AAAU,aAAG,AAAI;AAEhC,0BAAM,AAAI,OAAG,IAAI,AAAO,QAAC,AAAsB,AAAC;AAChD,AAAE,AAAC,wBAAC,AAAc,mBAAK,AAAI,AAAC,MAAC,AAAC;AAC5B,AAAI,6BAAC,AAAM,OAAC,AAAc,AAAC;AAC3B,AAAsF;AACtF,AAAQ,oCAAI,AAAc,eAAC,AAAM;AACjC,AAAc,yCAAG,AAAI,AACvB;AAAC;AACD,AAAI,yBAAC,AAAM,OAAC,AAAU,YAAE,AAAU,YAAE,AAAI,AAAC;AACzC,AAAS,8BAAC,AAAI,KAAC,AAAM,OAAC,AAAI,AAAC,AAAC;AAC5B,AAAU,iCAAG,AAAQ,AACvB;AAAC;AAED,sBAAM,AAAQ,WAAG,AAAgB,mBAAG,AAAU;AAC9C,AAAE,AAAC,oBAAC,AAAQ,aAAK,AAAC,AAAC,GAAC,AAAC;AACnB,AAAE,AAAC,wBAAC,AAAc,mBAAK,AAAI,AAAC,MAAC,AAAC;AAC5B,8BAAM,IAAI,AAAK,AAAC,yBAAmB,AAAI,IAAgC,AAAC,AAC1E;AAAC;AACD,AAAc,qCAAG,AAAU,WAAC,AAAK,MAAC,AAAU,YAAE,AAAU,aAAG,AAAQ,AAAC,AACtE;AAAC;AAED,AAAU,8BAAI,AAAgB;AAC9B,AAAE,AAAC,oBAAC,AAAU,cAAI,AAAG,AAAC,KAAC,AAAC;AACtB,AAAE,AAAC,wBAAC,AAAc,mBAAK,AAAI,AAAC,MAAC,AAAC;AAC5B,AAAQ,iCAAC,AAAI,KAAC,AAAQ,AAAC;AACvB,AAAS,kCAAC,AAAI,KAAC,AAAe,gBAAC,AAAc,AAAC,AAAC,AACjD;AAAC;AACD,AAAK,AACP;AAAC,AACD,AAAI,uBAAC,AAAE,AAAC,IAAC,AAAc,mBAAK,AAAI,AAAC,MAAC,AAAC;AACjC,AAAY;AACZ,AAAc,qCAAG,AAAM,OAAC,AAAI,KAAC,AAAc,AAAC,AAC9C;AAAC,AACH;AAAC;AAED,kBAAM,AAAS,qBAAY,AAAM,iBAAE,AAAW,aAAE,AAAY,AAAE,AAAE;AAA9B,uBAA+B,AAAW,cAAG,AAAY,AAAC;aAA1E,AAAQ;AAC1B,AAAE,AAAC,gBAAC,AAAS,cAAK,AAAQ,AAAC,UAAC,AAAC;AAC3B,sBAAM,IAAI,AAAK,AAAC,yBAAmB,AAAI,mCAA+B,AAAQ,kBAAU,AAAS,SAAE,AAAC,AACtG;AAAC;AAED,AAAM,mBAAC,EAAC,AAAS,WAAE,AAAK,OAAE,AAAQ,AAAC,AACrC;;AAAC,AACF;;uDAED,AAAsD;;AACtD,MAAM,AAAsB,yBAAG,AAAE;AACjC,MAAM,AAAO,UAAG,AAAO,QAAC,AAAe,AAAC;AAExC,yBAAyB,AAAa;AACpC,UAAM,AAAI,OAAG,IAAI,AAAO,QAAC,AAAsB,AAAC;AAChD,AAAI,SAAC,AAAM,OAAC,AAAK,AAAC;AAClB,AAA8L;AAC9L,AAAM,WAAC,AAAM,OAAC,AAAI,AAAC,AACrB;AAAC;AAED,gBAAgB,AAAS;AACvB,AAAM,WAAC,AAAI,KAAC,AAAM,AAAE,SAAC,AAAQ,SAAC,AAAQ,AAAC,AACzC;AAAC","sourcesContent":["import { FileChunks } from \"builder-util-runtime/out/blockMapApi\"\nimport { read } from \"fs-extra-p\"\nimport { Rabin } from \"rabin-bindings\"\n\nexport class ContentDefinedChunker {\n  async computeChunks(fd: number, start: number, end: number, name: string): Promise<FileChunks> {\n    const fileSize = end - start\n    const buffer = Buffer.allocUnsafe(Math.min(4 * 1024 * 1024, fileSize))\n\n    const rabin = Rabin()\n    const avgBits = 12\n    const min = 8 * 1024\n    // see note in the nsis.ts about archive dict size\n    const max = 32 * 1024\n    rabin.configure(avgBits, min, max)\n\n    const checksums: Array<string> = []\n    const allSizes: Array<number> = []\n\n    let tailBufferData: Buffer | null = null\n    let readOffset = start\n    while (true) {\n      const actualBufferSize = Math.min(end - readOffset, buffer.length)\n      await read(fd, buffer, 0, actualBufferSize, readOffset)\n\n      const dataBuffer: Buffer = buffer.length === actualBufferSize ? buffer : buffer.slice(0, actualBufferSize)\n      const sizes: Array<number> = []\n      rabin.fingerprint([dataBuffer], sizes)\n\n      let chunkStart = 0\n      for (const size of sizes) {\n        allSizes.push(size)\n        let chunkEnd = chunkStart + size\n\n        const hash = new Blake2s(CHECKSUM_OUTPUT_LENGTH)\n        if (tailBufferData !== null) {\n          hash.update(tailBufferData)\n          // if there is the tail data (already processed by rabin data), first size includes it\n          chunkEnd -= tailBufferData.length\n          tailBufferData = null\n        }\n        hash.update(dataBuffer, chunkStart, size)\n        checksums.push(digest(hash))\n        chunkStart = chunkEnd\n      }\n\n      const tailSize = actualBufferSize - chunkStart\n      if (tailSize !== 0) {\n        if (tailBufferData !== null) {\n          throw new Error(`Internal error (${name}): tailBufferData must be null`)\n        }\n        tailBufferData = dataBuffer.slice(chunkStart, chunkStart + tailSize)\n      }\n\n      readOffset += actualBufferSize\n      if (readOffset >= end) {\n        if (tailBufferData !== null) {\n          allSizes.push(tailSize)\n          checksums.push(computeChecksum(tailBufferData))\n        }\n        break\n      }\n      else if (tailBufferData !== null) {\n        // copy data\n        tailBufferData = Buffer.from(tailBufferData)\n      }\n    }\n\n    const totalSize = allSizes.reduce((accumulator, currentValue) => accumulator + currentValue)\n    if (totalSize !== fileSize) {\n      throw new Error(`Internal error (${name}): size mismatch: expected: ${fileSize}, got: ${totalSize}`)\n    }\n\n    return {checksums, sizes: allSizes}\n  }\n}\n\n// base64 - should be divisible by 3 to avoid paddings\nconst CHECKSUM_OUTPUT_LENGTH = 18\nconst Blake2s = require(\"../blake2s.js\")\n\nfunction computeChecksum(chunk: Buffer) {\n  const hash = new Blake2s(CHECKSUM_OUTPUT_LENGTH)\n  hash.update(chunk)\n  // node-base91 doesn't make a lot of sense - 29KB vs 30KB Because for base64 string value in the yml never escaped, but node-base91 often escaped (single quotes) and it adds extra 2 symbols.\n  return digest(hash)\n}\n\nfunction digest(hash: any) {\n  return hash.digest().toString(\"base64\")\n}\n"]}
